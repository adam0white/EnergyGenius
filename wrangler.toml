name = "energy-genius"
main = "src/worker/index.ts"
compatibility_date = "2025-11-11"
account_id = "a20259cba74e506296745f9c67c1f3bc"
workers_dev = false

[[routes]]
pattern = "genius.adamwhite.work"
custom_domain = true

[observability]
enabled = true

[observability.traces]
enabled = true

[assets]
directory = "./dist"

[ai]
binding = "AI"
remote = true

[vars]
# Optimized for 6-8x faster inference (80+ tokens/sec vs 10-15 tokens/sec)
# Expected response time: 15-20s (down from 45-60s)
# Cost reduction: 83% on input tokens ($0.045 vs $0.293/M)
# Trade-off: Slightly less sophisticated reasoning, but sufficient for energy plan scoring
AI_MODEL_FAST = "@cf/meta/llama-3.1-8b-instruct-fast"

# Fallback model for complex reasoning if needed (retained previous fast model)
# This can be used for A/B testing or fallback scenarios
AI_MODEL_ACCURATE = "@cf/meta/llama-3.3-70b-instruct-fp8-fast"

ENABLE_MOCK_DATA = "true"
ENABLE_SSE = "false"
