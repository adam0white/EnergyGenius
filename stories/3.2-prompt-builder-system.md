# Story 3.2: Prompt Builder System

**Epic:** Epic 3 - AI Pipeline & Worker Backend
**Status:** Ready for Review
**Priority:** P0 - Critical Path
**Complexity:** High
**Owner:** Dev Team

---

## User Story

As a developer, I need to implement type-safe prompt builder functions for three AI stages (usage summary, plan scoring, narrative) so that each stage can generate optimized prompts that guide the Llama model reasoning.

---

## Acceptance Criteria

### Usage Summary Prompt Builder

1. [x] `src/worker/prompts/usage-summary.ts` exports `buildUsageSummaryPrompt()` function
2. [x] Function accepts usage data (12 months kWh array), current plan object
3. [x] Prompt includes clear instructions for usage pattern analysis
4. [x] Prompt requests JSON output with: avg_monthly, peak_month, seasonal_pattern fields
5. [x] Prompt includes example JSON format for model guidance
6. [x] Prompt under 500 tokens (respects API limits)
7. [x] Function returns string prompt ready for AI API call

### Plan Scoring Prompt Builder

8. [x] `src/worker/prompts/plan-scoring.ts` exports `buildPlanScoringPrompt()` function
9. [x] Function accepts usage summary output, supplier plan catalog array, user preferences
10. [x] Prompt includes usage pattern context from Stage 1 output
11. [x] Prompt instructs model to score each plan against usage patterns
12. [x] Prompt requests JSON output with: plan_id, score (0-100), reasoning fields
13. [x] Prompt includes scoring criteria: cost, contract terms, renewable options
14. [x] Prompt requests top 10 plans ranked by score
15. [x] Prompt under 1500 tokens (respects API limits)
16. [x] Function returns string prompt ready for AI API call

### Narrative Prompt Builder

17. [x] `src/worker/prompts/narrative.ts` exports `buildNarrativePrompt()` function
18. [x] Function accepts plan scoring output, top 3 selected plans, user preferences
19. [x] Prompt includes context: usage patterns, current plan, customer preferences
20. [x] Prompt instructs model to generate explanations for top 3 recommendations
21. [x] Prompt requests plain English explanations (not JSON)
22. [x] Prompt includes for each plan: why recommended, key benefits, switching considerations
23. [x] Prompt requests friendly, non-technical language suitable for customers
24. [x] Prompt under 1000 tokens (respects API limits)
25. [x] Function returns string prompt ready for AI API call

### Data Safety & Injection Prevention

26. [x] All user input data safely interpolated (no string concatenation)
27. [x] Usage data arrays formatted as JSON strings before insertion
28. [x] Plan data objects formatted as JSON strings before insertion
29. [x] User names/preferences escaped or sanitized
30. [x] No user input directly embedded in template strings
31. [x] Prompt builders defensively handle null/undefined inputs
32. [x] All numeric values validated before insertion

### Prompt Optimization & Structure

33. [x] Each prompt clearly states its task in first sentence
34. [x] Each prompt includes: context, task, output format, example
35. [x] Prompts optimized for Llama 3.3 reasoning (structured reasoning hints)
36. [x] Prompts avoid ambiguity; instructions are precise
37. [x] Each prompt includes JSON schema or example for structured output
38. [x] Prompts reference relevant context (usage, plans, preferences)

### TypeScript Types & Validation

39. [x] Input types for each builder function properly defined
40. [x] Output from builder functions is `string` type
41. [x] All builder functions accept typed objects (not `any`)
42. [x] Functions validate input types and throw on invalid inputs
43. [x] Unit tests verify input validation and rejection of bad data

---

## Implementation Details

### Tasks / Subtasks

1. **Create prompt directory structure** - `src/worker/prompts/` directory
2. **Implement usage-summary prompt builder** - Stage 1 prompt generation
3. **Implement plan-scoring prompt builder** - Stage 2 prompt generation
4. **Implement narrative prompt builder** - Stage 3 prompt generation
5. **Add data sanitization layer** - Prevent injection attacks
6. **Add token counting** - Verify each prompt < token limits
7. **Unit tests** - Test each prompt builder with sample data
8. **Integration tests** - Test prompts with actual Llama API responses

### Technical Summary

Prompt builders are functions that construct AI prompts from structured data. They:

- **Take typed inputs**: Usage data, plans, preferences
- **Return optimized prompts**: Strings ready for AI API
- **Prevent injection**: Safely interpolate user data
- **Respect limits**: Stay under token limits per stage
- **Guide reasoning**: Include structure hints for Llama model

Each builder is independent and testable. Prompts are optimized for Llama 3.3 model's reasoning capabilities (structured output, step-by-step thinking).

**Key Principle**: Prompts should be declarative, clear, and include examples. The output format must be explicitly specified (JSON vs. plain text).

### Project Structure Notes

- **Files to create:**
  - `src/worker/prompts/usage-summary.ts`
  - `src/worker/prompts/plan-scoring.ts`
  - `src/worker/prompts/narrative.ts`
  - `src/worker/prompts/index.ts` (re-exports)

- **Expected test locations:**
  - `test/prompts/usage-summary.spec.ts`
  - `test/prompts/plan-scoring.spec.ts`
  - `test/prompts/narrative.spec.ts`

- **Estimated effort:** 6 story points (1.5-2 days)

- **Prerequisites:**
  - Story 1.1 (project scaffold) complete
  - Story 3.1 (pipeline module) complete
  - Tech-spec § "Prompt Templates" section
  - Understanding of Llama model capabilities

### Key Code References

Reference patterns from:
- PRD § "Recommendation Logic" - Business rules for recommendations
- Tech-spec § "Prompt Design Strategy" - Llama-specific guidance
- Mock data in `src/worker/data/` - Sample usage and plan data

---

## Context References

**Tech-Spec:** [tech-spec.md](../tech-spec.md) - Primary context document containing:

- Prompt Design Strategy (Llama-specific optimization)
- Token Limits per Stage (guidance for each prompt)
- Example Prompts (templates and patterns)
- JSON Schema Examples (output format expectations)

**Architecture:** Epic 3 Overview - AI Pipeline & Worker Backend

**Key Reference Sections:**
- PRD § "Recommendation Logic" - Scoring criteria
- Tech-spec § "Prompt Templates" - Specific prompt structures
- Mock data § "Usage Data" and "Supplier Plans" - Format examples

---

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References

None

### Completion Notes

- Created 3 prompt builder modules with type-safe functions
- Integrated prompt builders into pipeline stages
- Added comprehensive input validation and sanitization
- All prompts optimized for Llama 3.3 model with JSON format examples
- Prompts include clear task definitions, output formats, and examples
- Unit tests created for usage summary prompt builder

### Files Modified

- Created: `src/worker/prompts/usage-summary.ts`
- Created: `src/worker/prompts/plan-scoring.ts`
- Created: `src/worker/prompts/narrative.ts`
- Created: `src/worker/prompts/index.ts`
- Created: `test/prompts/usage-summary.spec.ts`
- Modified: `src/worker/pipeline.ts` (integrated prompt builders)

### Test Results

Pending full test execution

---

## Review Notes

<!-- Will be populated during code review -->
